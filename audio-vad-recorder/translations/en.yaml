configuration:
  rtsp_url:
    name: "RTSP URL"
    description: >-
      Full RTSP or RTSPS stream URL of the camera
      (e.g. rtsps://192.168.1.10:7441/abcdef?enableSrtp).
  camera_name:
    name: "Camera name"
    description: >-
      A short label used in recorded file names
      (e.g. 'frontdoor' → frontdoor_20260225_143000.wav).
  vad_threshold:
    name: "VAD threshold"
    description: >-
      Speech detection sensitivity from 0.0 to 1.0.
      Lower values detect more sounds (more false positives),
      higher values require clearer speech.
      Recommended range: 0.5 – 0.8.
  pre_padding:
    name: "Pre-speech padding (seconds)"
    description: >-
      Amount of silence to include BEFORE detected speech begins.
      Prevents the very first syllable from being cut off.
      Typical value: 0.3 – 0.7.
  post_padding:
    name: "Post-speech padding (seconds)"
    description: >-
      How long to keep recording silence AFTER speech ends
      before saving the file. Also acts as the silence timeout —
      if no speech is detected for this many seconds, the recording
      is finalized. Gives recordings a natural trailing breath.
      Typical value: 1.0 – 2.0.
  min_speech_duration:
    name: "Minimum speech duration (seconds)"
    description: >-
      Recordings shorter than this are discarded as false positives
      (door slams, coughs, etc.). Set to 0 to keep everything.
  max_recording_duration:
    name: "Maximum recording duration (seconds)"
    description: >-
      Hard limit on a single recording length.
      Prevents runaway buffer growth if someone talks for a very long time
      (e.g. a TV left on). The file is saved and a new recording starts.
  whisper_enabled:
    name: "Enable Whisper transcription"
    description: >-
      When enabled, each recorded speech segment is sent to a
      Whisper-compatible API for transcription. The text is saved
      as a .txt file alongside the .wav recording.
  whisper_api_url:
    name: "Whisper API URL"
    description: >-
      OpenAI-compatible transcription endpoint.
      Groq (free): https://api.groq.com/openai/v1/audio/transcriptions
      OpenAI: https://api.openai.com/v1/audio/transcriptions
      Local server: http://192.168.1.X:8000/v1/audio/transcriptions
  whisper_api_key:
    name: "Whisper API key"
    description: >-
      API key for the transcription service. Required for Groq and OpenAI.
      For a local server without auth, leave empty.
  whisper_model:
    name: "Whisper model"
    description: >-
      Model name to use for transcription.
      Groq: whisper-large-v3 (recommended).
      OpenAI: whisper-1.
      Local: depends on your server configuration.
  whisper_language:
    name: "Language"
    description: >-
      Language code for transcription (e.g. pl, en, de, fr).
      Helps Whisper produce more accurate results.
